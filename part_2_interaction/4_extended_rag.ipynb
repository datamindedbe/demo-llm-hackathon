{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import boto3\n",
    "import pprint\n",
    "from typing import Tuple, List, Callable, Optional\n",
    "\n",
    "BEDROCK_CLIENT = boto3.client('bedrock-agent-runtime', region_name='us-east-1') # note the region\n",
    "KNOWLEDGE_BASE_ID ='ECZYEUIJ59' # this is the id of the decisions knowledge base in english\n",
    "\n",
    "\n",
    "ssm_client = boto3.client('ssm', region_name='eu-west-1')\n",
    "open_ai_key = ssm_client.get_parameter(Name='llm-hackathon-openai-key')['Parameter']['Value']\n",
    "OPENAI_CLIENT = openai.OpenAI(\n",
    "    api_key=open_ai_key\n",
    ")\n",
    "\n",
    "\n",
    "GPT_4 = 'gpt-4-turbo'\n",
    "GPT_3 = 'gpt-3.5-turbo-0125'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper around the bedrock client retrieval method\n",
    "def retrieve(search_string, items=10):\n",
    "    retrievals = BEDROCK_CLIENT.retrieve(\n",
    "        knowledgeBaseId=KNOWLEDGE_BASE_ID,\n",
    "        retrievalQuery={\n",
    "            'text': search_string\n",
    "        },\n",
    "        retrievalConfiguration={\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': items\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return retrievals['retrievalResults']\n",
    "\n",
    "\n",
    "# wrapper around the openai api\n",
    "def generate(prompt:str, model)->str:\n",
    "    api_response = OPENAI_CLIENT.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    return api_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieval improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one method of improving RAG performance is by trying to improve our retrieval\n",
    "# here we can get creative\n",
    "\n",
    "def make_verbose(query: str) -> str:\n",
    "    model = GPT_3\n",
    "    prompt = f\"\"\"\n",
    "    Take the query given below and rephrase it in a slightly more verbose way - expanding on the concept of the question asked\n",
    "    specially in relation to flemish politics\n",
    "    query: {query}\n",
    "    \"\"\"\n",
    "    return generate(prompt, model)\n",
    "\n",
    "def attempt_answer(query: str) -> str:\n",
    "    model = GPT_3\n",
    "    prompt = f\"\"\"\n",
    "    Provide a hypothetical response to the query given below, the response should relate to flemish politics\n",
    "    query: {query}\n",
    "    \"\"\"\n",
    "    return generate(prompt, model)\n",
    "    \n",
    "\n",
    "def break_into_facets(query: str) -> List[str]:\n",
    "    model = GPT_3\n",
    "    facets = 3\n",
    "    prompt = f\"\"\"\n",
    "    Take the query given below and generate {facets} statements which could be related to it in the context of \n",
    "    flemish politics, the generated statements should ideally focus on different aspects of the query.\n",
    "    provide the statements as a list with each element starting with an *\n",
    "    query: {query}\n",
    "    \"\"\"\n",
    "    response = generate(prompt, model)\n",
    "    generated_facets = response.split('*')\n",
    "    return [item for item in generated_facets if len(item)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(make_verbose(\"farmers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(attempt_answer(\"what are we doing about the borders\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(break_into_facets(\"are we doing things for the climate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAG_retrieval_augmentation(query:str,model: str, num_retrivals:int, augmentation_method: Optional[Callable]=None)-> Tuple[str, str]:\n",
    "    \n",
    "    if augmentation_method:\n",
    "        retrieval_query = augmentation_method(query)\n",
    "    else:\n",
    "        retrieval_query = query\n",
    "\n",
    "\n",
    "    if type(retrieval_query) == str:\n",
    "        retrieval_query = [retrieval_query]\n",
    "\n",
    "    context_items_nested = [retrieve(item, num_retrivals) for item in retrieval_query]\n",
    "    context_items = []\n",
    "    [context_items.extend(item) for item in context_items_nested]\n",
    "\n",
    "\n",
    "    flat_items = [f\"{index} : {item['content']['text']}\" for index, item in enumerate(context_items)]\n",
    "    flat_items = \"\\n\".join(flat_items)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "                Answer the given question using only the information in the sources section below.\n",
    "                Respond in a conversational manner, not with a list.\n",
    "                Enter the index number of the source used between single square brackets, such as [1] or [2][3][4].\n",
    "                do not combine references together in one bracket\n",
    "\n",
    "                question:{query}\n",
    "                sources: {flat_items}\n",
    "                your answer:\n",
    "    \"\"\"\n",
    "    return generate(prompt, model), flat_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(RAG_retrieval_augmentation(\"healthcare\",GPT_4, 5, augmentation_method=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(RAG_retrieval_augmentation(\"healthcare\",GPT_4, 5, augmentation_method=make_verbose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(RAG_retrieval_augmentation(\"healthcare\",GPT_4, 5, augmentation_method=attempt_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(RAG_retrieval_augmentation(\"healthcare\",GPT_4, 5, augmentation_method=break_into_facets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what are we doing for children\"\n",
    "facets = break_into_facets(query)\n",
    "pprint.pprint(facets)\n",
    "\n",
    "for facet in facets:\n",
    "    retrievals = retrieve(facet, 5)\n",
    "    scores = [item['score'] for item in retrievals]\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the crux is that we want to ensure that the most relevant pieces of context are closest to the edge of the context window\n",
    "\n",
    "def rerank_on_similarity_score(retrievals: List[dict])-> List[dict]:\n",
    "    # this is a simple reranker which just looks at similarity scores\n",
    "    # use in combination with retrieval augmentation methods which sample the vector db multiple times\n",
    "    return sorted(retrievals, key=lambda k: k['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAG_retrieval_augmentation_and_reranking(query:str,model: str, num_retrivals:int,\n",
    "    augmentation_method: Optional[Callable] = None, reranking_method: Optional[Callable]= None)-> Tuple[str, str]:\n",
    "    \n",
    "\n",
    "    if augmentation_method:\n",
    "        retrieval_query = augmentation_method(query)\n",
    "    else:\n",
    "        retrieval_query = query\n",
    "\n",
    "\n",
    "    if type(retrieval_query) == str:\n",
    "        retrieval_query = [retrieval_query]\n",
    "\n",
    "    context_items_nested = [retrieve(item, num_retrivals) for item in retrieval_query]\n",
    "    context_items = []\n",
    "    [context_items.extend(item) for item in context_items_nested]\n",
    "\n",
    "\n",
    "    if reranking_method:\n",
    "        context_items = reranking_method(context_items)\n",
    "\n",
    "\n",
    "    flat_items = [f\"{index} : {item['content']['text']}\" for index, item in enumerate(context_items)]\n",
    "    flat_items = \"\\n\".join(flat_items)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "                Answer the given question using only the information in the sources section below.\n",
    "                Respond in a conversational manner, not with a list.\n",
    "                Enter the index number of the source used between single square brackets, such as [1] or [2][3][4].\n",
    "                do not combine references together in one bracket\n",
    "\n",
    "                question:{query}\n",
    "                sources: {flat_items}\n",
    "                your answer:\n",
    "    \"\"\"\n",
    "    return generate(prompt, model), flat_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(RAG_retrieval_augmentation_and_reranking(\"what are we doing for children\",GPT_4, 5,\n",
    "                augmentation_method=break_into_facets,\n",
    "                reranking_method=rerank_on_similarity_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
